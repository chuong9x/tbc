<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="bc.css">
<script src="run_prettify.js" type="text/javascript"></script>
<!--
<script src="https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js" type="text/javascript"></script>
-->
</head>

<!---

- blog on elasticsearch


 #RevitAPI @AutodeskRevit #aec #bim #dynamobim @AutodeskForge http://bit.ly/devdays2016online

&ndash; 
...

-->

### Revit API Question Answering System


first thing to do: customise a search engine
elastic search has NLP
available in several languages
java based
lucene os state of art search engine
rest api
semantic analysis
create own extractor, domain information extraction

1) Dans un premier temps, une approche par moteur de recherche spécialisé est probablement la plus efficace, al moins risquée et la plus rapide à mettre en oeuvre. Cela peut constituer un plan de contingence (contingency plan) ou une référence (baseline) à l'utilisation d'un système plus sophistiqué faisant appel à l'apprentissage statistique conventionnel voire à de l'apprentissage profond. Je verrais très bien un projet réalisé par étapes.

second thing step by
machine learning, not deep learning
many algorithms like random forest, xg boost
you need samples

2) Algorithmes d'apprentissage statistique conventionnels

Ce qui marche le mieux en apprentissage statistique demeure l'apprentissage supervisé à partir d'exemples/observations étiquetés. C'est encore plus vrai pour l'apprentissage profond, où l'apprentissage non-supervisé relève davantage de la recherche que du domaine des applications.

Avec des algorithmes d'apprentissage conventionnels, les meilleurs étant les méthodes ensemblistes (explications plus bas), ont peut obtenir de bons résultats avec quelques centaines d'exemples étiquetés (labeled samples). 

Les algos ensemblistes sont des méta-algorithmes où l'on combine les résultats d'un ensemble de classificateurs simples. Les plus connues sont le bagging (ré-échantillonnage et vote ou moyenne) et le boosting (pondération des classificateurs). Concrètement on parle de forêt d'arbres aléatoires (Random Forest), de Gradient Tree Boosting et surtout de XGBoost (Extreme Gradient Boosting).

third step: deep learning techniques
needs to consume a lot of data

last friday
380 people at the meetup
including startups
challenges regarding ui

3) Apprentissage profond

Le principal obstacle pour l'utilisation de l'apprentissage profond est de disposer de suffisamment de données. Typiquement, la règle du pouce est qu'un algorithme d'apprentissage profond supervisé atteindra des performances acceptables avec environ 5000 exemples étiquetés (labeled samples) par question et dépassera la performance humaine lorsqu'il sera entraîné avec un ensemble de données contenant au moins 10 millions d'exemples / observations.

Dans le cas d'un nombre insuffisants de données, il existe en gros quatre solutions potentielles. L'étiquetage « par la foule » (crowdsourcing), l'apprentissage semi-supervisé (étiquetage automatique ou semi-automatique) à partir de jeux de données importants mais non étiquetés,  l'amplification de données (data augmentation) où l'on génère automatiquement des variantes des données disponibles et le transfert d'apprentissage (learning transfer) qui consiste à ajouter à un réseau de neurones profonds pré-entraînés sur un énorme corpus générique une couche applicative spécifique.

google provides good apis to figure out context, e.g. speaking of specific products. not tensorflow, that's for deep learning; more a standard thing.

test using commercial apis to compare with a custom solution: ibm, microsoft, amazon.

it does not take a lot of time, just have a look, pull some examples.

sacha has a sample using nlp field, very well known.

java based, generates a graph, connect different extractors, post-tagging, very good algorithm, good documentation.

taln traitement automatique language naturel

work with a consultant

create a good knowledge base:
just documents and knowing how to connect them, unstructured document content, how are they related
elastic search engine can do this
when to display a result: display portion of text already, not only links
focus
have a look at web semantic
spark-ql
RDF links
a bit old, used five years ago
creating an ontology is tough, and that is not what works well
better: dictionaries, simple bag of words related to a topic
first step: create a search engine and ask the system after indexing all words in the content, ask for frequiencies of terms, analuys what you have, understand the content
nlp techniques, develop own extractor
it creates topics based on bag of words
use machine learning to cluster words
but first just do manual search

http://stackoverflow.com/questions/8772692/semantic-search-with-nlp-and-elasticsearch#8774917

https://blog.conceptnet.io/2016/11/03/conceptnet-5-5-and-conceptnet-io/

https://code.google.com/archive/p/maui-indexer/

- [21 - 1 - What is Question Answering-NLP-Dan Jurafsky & Chris Manning](https://youtu.be/DAHZPL6voc4)
  https://www.youtube.com/shared?ci=O_SFLokE3so
  Published on 30 Apr 2012
  If you are interest on more free online course info, welcome to: [opencourseonline.com](http://opencourseonline.com)
  Professor Dan Jurafsky & Chris Manning are offering a free online course on Natural Language Processing starting in March 19, 2012. http://www.nlp-class.org/
  Offered by Coursera: https://www.coursera.org/

- [1 - 1 - Course Introduction - Stanford NLP - Professor Dan Jurafsky & Chris Manning](https://youtu.be/nfoudtpBV68)

<center>
<img src="img/.png" alt="" width="505"/>
</center>

#### <a name="2"></a>


#### <a name="3"></a>

#### <a name="4"></a>


